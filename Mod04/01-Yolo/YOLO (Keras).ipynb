{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with YOLO in Keras\n",
    "\n",
    "In this exercise, you'll use a Keras implementation of YOLO to detect objects in an image.\n",
    "\n",
    "> **Important**: Using the YOLO model is resource-intensive. before running the code in this notebook, shut down all other notebooks in this library (In each open notebook other than this one, on the **File** menu, click **Close and Halt**). If you experience and Out-of-Memory (OOM) error when running code in this notebook, shut down this entire library, and then reopen it and open only this notebook.\n",
    "\n",
    "## Install Keras\n",
    "First, let's ensure that the latest version of Keras is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Convert YOLO weights\n",
    "YOLO is based on the Darknet model architecture - an open-source model written in C. The creators of this model have provided pre-trained weights that were trained on the [Common Objects in Context (COCO) dataset](cocodataset.org) - a common set of sample images for computer vision research.\n",
    "\n",
    "Run the following cell to download the weights, and convert them into a suitable format for use with Keras.\n",
    "\n",
    "> _**Note**: This can take some time to run_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Traceback (most recent call last):\n",
      "  File \"yolo_keras/convert.py\", line 262, in <module>\n",
      "    _main(parser.parse_args())\n",
      "  File \"yolo_keras/convert.py\", line 73, in _main\n",
      "    weights_file = open(weights_path, 'rb')\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Dennis Lam/yolo3.weights'\n"
     ]
    }
   ],
   "source": [
    "!wget https://pjreddie.com/media/files/yolov3.weights -O ~/yolo3.weights\n",
    "!python yolo_keras/convert.py yolo_keras/yolov3.cfg ~/yolo3.weights ~/yolo.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the weights have been downloaded, the layers in the model are described.\n",
    "\n",
    "## Load the Weights into a Keras Model\n",
    "\n",
    "Now that we have the weights, we can load them into a Keras model.\n",
    "\n",
    "> **Note** The code to implement the Keras model is in **yolo_keras/model.py**. Additionally, **yolo_keras/utils.py** contains some functions that are used to assemble and use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'C:\\Users\\Dennis Lam\\yolo.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-864748d9e20e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mhome\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"~\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhome\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"yolo.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0myolo_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# Generate output tensor targets for bounding box predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'write'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_is_path_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'C:\\Users\\Dennis Lam\\yolo.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "\n",
    "from yolo_keras.utils import *\n",
    "from yolo_keras.model import *\n",
    "\n",
    "# Get the COCO classes on which the model was trained\n",
    "classes_path = \"yolo_keras/coco_classes.txt\"\n",
    "with open(classes_path) as f:\n",
    "    class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names] \n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Get the anchor box coordinates for the model\n",
    "anchors_path = \"yolo_keras/yolo_anchors.txt\"\n",
    "with open(anchors_path) as f:\n",
    "    anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    anchors = np.array(anchors).reshape(-1, 2)\n",
    "num_anchors = len(anchors)\n",
    "\n",
    "# Set the expected image size for the model\n",
    "model_image_size = (416, 416)\n",
    "\n",
    "# Create YOLO model\n",
    "home = os.path.expanduser(\"~\")\n",
    "model_path = os.path.join(home, \"yolo.h5\")\n",
    "yolo_model = load_model(model_path, compile=False)\n",
    "\n",
    "# Generate output tensor targets for bounding box predictions\n",
    "# Predictions for individual objects are based on a detection probability threshold of 0.3\n",
    "# and an IoU threshold for non-max suppression of 0.45\n",
    "input_image_shape = K.placeholder(shape=(2, ))\n",
    "boxes, scores, classes = yolo_eval(yolo_model.output, anchors, len(class_names), input_image_shape,\n",
    "                                    score_threshold=0.3, iou_threshold=0.45)\n",
    "\n",
    "print(\"YOLO model ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model to Detect Objects\n",
    "\n",
    "Now we're ready to use the YOLO model to detect objects in images.\n",
    "\n",
    "### Create functions to detect and display objects\n",
    "We'll create a couple of functions:\n",
    "\n",
    "- **detect_objects**: Submits an image to the model and returns predicted object locations\n",
    "- **show_objects**: Displays the image with a bounding box fo each detected object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image):\n",
    "    \n",
    "    # normalize and reshape image data\n",
    "    image_data = np.array(image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "    # Predict classes and locations using Tensorflow session\n",
    "    sess = K.get_session()\n",
    "    out_boxes, out_scores, out_classes = sess.run(\n",
    "                [boxes, scores, classes],\n",
    "                feed_dict={\n",
    "                    yolo_model.input: image_data,\n",
    "                    input_image_shape: [image.size[1], image.size[0]],\n",
    "                    K.learning_phase(): 0\n",
    "                })\n",
    "    return out_boxes, out_scores, out_classes\n",
    "\n",
    "def show_objects(image, out_boxes, out_scores, out_classes):\n",
    "    import random\n",
    "    from PIL import Image\n",
    "    import matplotlib.patches as patches\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    %matplotlib inline \n",
    "    \n",
    "    # Set up some display formatting\n",
    "    cmap = plt.get_cmap('tab20b')\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, 20)]\n",
    "\n",
    "    # Plot the image\n",
    "    img = np.array(image)\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(1, figsize=(12,9))\n",
    "    ax.imshow(img)\n",
    "\n",
    "    # Set up padding for boxes\n",
    "    img_size = model_image_size[0]\n",
    "    pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
    "    pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
    "    unpad_h = img_size - pad_y\n",
    "    unpad_w = img_size - pad_x\n",
    "\n",
    "    # Use a random color for each class\n",
    "    unique_labels = np.unique(out_classes)\n",
    "    n_cls_preds = len(unique_labels)\n",
    "    bbox_colors = random.sample(colors, n_cls_preds)\n",
    "\n",
    "    # process each instance of each class that was found\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "\n",
    "        # Get the class name\n",
    "        predicted_class = class_names[c]\n",
    "        # Get the box coordinate and probability score for this instance\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "\n",
    "        # Format the label to be added to the image for this instance\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "\n",
    "        # Get the box coordinates\n",
    "        top, left, bottom, right = box\n",
    "        y1 = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        x1 = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        y2 = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        x2 = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "\n",
    "        # Set the box dimensions\n",
    "        box_h = ((y2 - y1) / unpad_h) * img.shape[0]\n",
    "        box_w = ((x2 - x1) / unpad_w) * img.shape[1]\n",
    "        y1 = ((y1 - pad_y // 2) / unpad_h) * img.shape[0]\n",
    "        x1 = ((x1 - pad_x // 2) / unpad_w) * img.shape[1]\n",
    "        \n",
    "        # Add a box with the color for this class\n",
    "        color = bbox_colors[int(np.where(unique_labels == c)[0])]\n",
    "        bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(bbox)\n",
    "        plt.text(x1, y1, s=label, color='white', verticalalignment='top',\n",
    "                bbox={'color': color, 'pad': 0})\n",
    "        \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the functions with test images\n",
    "Now we're ready to get some predictions from our test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "test_dir = \"../../data/object_detection\"\n",
    "for image_file in os.listdir(test_dir):\n",
    "    \n",
    "    # Load image\n",
    "    img_path = os.path.join(test_dir, image_file)\n",
    "    image = Image.open(img_path)\n",
    "    \n",
    "    # Resize image for model input\n",
    "    image = letterbox_image(image, tuple(reversed(model_image_size)))\n",
    "\n",
    "    # Detect objects in the image\n",
    "    out_boxes, out_scores, out_classes = detect_objects(image)\n",
    "\n",
    "    # How many objects did we detect?\n",
    "    print('Found {} objects in {}'.format(len(out_boxes), image_file))\n",
    "\n",
    "    # Display the image with bounding boxes\n",
    "    show_objects(image, out_boxes, out_scores, out_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements and Citations\n",
    "The original YOLO documentation is at https://pjreddie.com/darknet/yolo/.\n",
    "\n",
    "The Keras implementation of YOLO used in this exercise is based on the work of qqwweee at https://github.com/qqwweee/keras-yolo3, with some simplifications.\n",
    "\n",
    "The test images used in this exercise are from the PASCAL Visual Object Classes Challenge (VOC2007) dataset at http://host.robots.ox.ac.uk/pascal/VOC/voc2007/.\n",
    "\n",
    "\n",
    "    @misc{pascal-voc-2007,\n",
    "        author = \"Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.\",\n",
    "        title = \"The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2007 {(VOC2007)} {R}esults\",\n",
    "        howpublished = \"http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html\"}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
